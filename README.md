# Spark_videos

https://www.youtube.com/@hackprotech/videos

## 1. Download Spark

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/bf4f7471-5ff8-4158-a5e8-d63b89ddc1cc)

Unzip the "spark-3.5.0-bin-hadoop3.tgz"

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/39fbee24-681a-47e3-8f63-baea221ec099)

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/3bca82b7-b6e9-4124-b3a4-75506da8395a)

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/8353cd13-5d6c-4d72-bf18-337796c3e8ff)

## 2. Set Spark environmental variable

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/993e30be-d134-4364-bd56-1135dcf6084a)

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/17011565-587c-4b1a-98f7-5313cf4b21c2)

## 3. Check the spark-shell is installed

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/e453931d-da41-4204-a750-a8c416121322)


## 4. Install IntelliJ Community Edition

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/b86a6bf1-1217-46b1-bc82-ffc584830f1f)

## 5. Create a new Scala project with IntelliJ

Run IntelliJ Community and confirm "Scala" plugin is installed

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/b3b48661-b32f-426a-af10-e2312afa3456)

Select "Projects" in the left menu, and then click on the "New Project" button

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/ffe80d72-07af-4e9b-ba30-e48318482982)

Before we input the new project data, copy Spark version and the Scala Version

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/55573bfe-cf67-4f32-8534-e2c92cc4fcef)

Then we input the new project data

![image](https://github.com/luiscoco/Spark_videos/assets/32194879/3d1d8dd3-8cae-4932-bd7c-d4a1038f3903)

## 6.





